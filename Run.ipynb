{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High res drone imagery with TorchGeo\n",
    "\n",
    "This notebook demonstrates how to use the `OpenAerialMap` dataset in TorchGeo to train a instance segmentation model for building detection.\n",
    "\n",
    "**Features showcased:**\n",
    "1. **Catalog Search:** Querying available imagery using the new `search=True` mode.\n",
    "2. **Data Download:** Downloading specific high-resolution drone imagery.\n",
    "3. **Intersection Dataset:** combining raster (OAM) and vector (OSM) data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torchgeo.datasets import OpenStreetMap, OpenAerialMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Region of Interest\n",
    "\n",
    "We define a bounding box for **Banepa Municipality, Nepal**. This area has good drone coverage in OpenAerialMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = Path('data/banepa')\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_BBOX = [\n",
    "  85.51176609880189,\n",
    "  27.625518932561256,\n",
    "  85.52513148143508,\n",
    "  27.63551883131749\n",
    "]\n",
    "\n",
    "TEST_BBOX = [\n",
    "  85.53039880381334,\n",
    "  27.62456651360527,\n",
    "  85.53606027956683,\n",
    "  27.629042810653335\n",
    "]\n",
    "\n",
    "VAL_BBOX = [\n",
    "  85.51883176039746,\n",
    "  27.63560,\n",
    "  85.52308324197179,\n",
    "  27.63833629629815\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Browse Available Imagery\n",
    "\n",
    "We use `search=True` to query the catalog without downloading files. This allows us to inspect metadata and choose the best image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for available images...\n",
      "Found 4 available images\n",
      "\n",
      "Use .search_results to view.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Provider</th>\n",
       "      <th>GSD</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6708341a4a0ab60001b0b94d</td>\n",
       "      <td>2024-10-10T20:07:54.049+00:00</td>\n",
       "      <td>satellite</td>\n",
       "      <td>Maxar</td>\n",
       "      <td>0.345278</td>\n",
       "      <td>Maxar 105001003E1F0500 Nepal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67084ad84a0ab60001b0b95b</td>\n",
       "      <td>2024-10-10T21:44:56.060+00:00</td>\n",
       "      <td>satellite</td>\n",
       "      <td>Maxar</td>\n",
       "      <td>0.345283</td>\n",
       "      <td>Maxar 1040010095519A00 Nepal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62d86c65d8499800053796c4</td>\n",
       "      <td>2022-04-15T19:00:00Z</td>\n",
       "      <td>uav</td>\n",
       "      <td>Geomatics Engineering Society</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>UAV Images of Banepa Municipality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59e62b743d6412ef72209204</td>\n",
       "      <td></td>\n",
       "      <td>satellite</td>\n",
       "      <td>Digital Globe</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15APR27052125-S3DS_R14C5-054335918020_01_P001.TIF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID                           Date   Platform  \\\n",
       "0  6708341a4a0ab60001b0b94d  2024-10-10T20:07:54.049+00:00  satellite   \n",
       "1  67084ad84a0ab60001b0b95b  2024-10-10T21:44:56.060+00:00  satellite   \n",
       "2  62d86c65d8499800053796c4           2022-04-15T19:00:00Z        uav   \n",
       "3  59e62b743d6412ef72209204                                 satellite   \n",
       "\n",
       "                        Provider       GSD  \\\n",
       "0                          Maxar  0.345278   \n",
       "1                          Maxar  0.345283   \n",
       "2  Geomatics Engineering Society  0.031627   \n",
       "3                  Digital Globe  0.400000   \n",
       "\n",
       "                                               Title  \n",
       "0                       Maxar 105001003E1F0500 Nepal  \n",
       "1                       Maxar 1040010095519A00 Nepal  \n",
       "2                  UAV Images of Banepa Municipality  \n",
       "3  15APR27052125-S3DS_R14C5-054335918020_01_P001.TIF  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Searching for available images...')\n",
    "browser = OpenAerialMap(paths=WORK_DIR, bbox=TRAIN_BBOX, search=True, max_items=5)\n",
    "\n",
    "if browser.search_results is not None:\n",
    "    display(browser.search_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Datasets\n",
    "\n",
    "We select a specific Image ID from the search results above and download it.\n",
    "We also download OpenStreetMap building footprints for the same area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = [TRAIN_BBOX, VAL_BBOX, TEST_BBOX ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing OpenAerialMap (Image Layer)...\n",
      "Using OpenAerialMap image: UAV Images of Banepa Municipality\n",
      "  ID: 62d86c65d8499800053796c4\n",
      "  Date: 2022-04-15T19:00:00Z\n",
      "  Platform: uav\n",
      "  Provider: Geomatics Engineering Society\n",
      "  GSD: 0.0316273953754\n",
      "  License: CC-BY-4.0\n",
      "Starting download of 378 tiles...\n",
      "Download complete.\n",
      "Initializing OpenStreetMap (Mask Layer)...\n",
      "Using OpenAerialMap image: UAV Images of Banepa Municipality\n",
      "  ID: 62d86c65d8499800053796c4\n",
      "  Date: 2022-04-15T19:00:00Z\n",
      "  Platform: uav\n",
      "  Provider: Geomatics Engineering Society\n",
      "  GSD: 0.0316273953754\n",
      "  License: CC-BY-4.0\n",
      "Starting download of 40 tiles...\n",
      "Download complete.\n",
      "Initializing OpenStreetMap (Mask Layer)...\n",
      "Using OpenAerialMap image: UAV Images of Banepa Municipality\n",
      "  ID: 62d86c65d8499800053796c4\n",
      "  Date: 2022-04-15T19:00:00Z\n",
      "  Platform: uav\n",
      "  Provider: Geomatics Engineering Society\n",
      "  GSD: 0.0316273953754\n",
      "  License: CC-BY-4.0\n",
      "Starting download of 72 tiles...\n",
      "Download complete.\n",
      "Initializing OpenStreetMap (Mask Layer)...\n"
     ]
    }
   ],
   "source": [
    "# Selected Image ID (from search results above)\n",
    "IMAGE_ID = '62d86c65d8499800053796c4'\n",
    "ZOOM_LEVEL = 19\n",
    "CHIP_SIZE_PX = 512\n",
    "\n",
    "print('Initializing OpenAerialMap (Image Layer)...')\n",
    "\n",
    "\n",
    "folder = ['train', 'val', 'test']\n",
    "\n",
    "i = 0\n",
    "for bbox_d in all_datasets:\n",
    "    oam_dataset = OpenAerialMap(\n",
    "        paths=os.path.join(WORK_DIR,folder[i],'source'),\n",
    "        bbox=bbox_d,\n",
    "        zoom=ZOOM_LEVEL,\n",
    "        download=True,\n",
    "        image_id=IMAGE_ID,\n",
    "        tile_size=CHIP_SIZE_PX,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print('Initializing OpenStreetMap (Mask Layer)...')\n",
    "    OSM_CLASSES = [{'name': 'building', 'selector': [{'building': '*'}]}]\n",
    "\n",
    "    osm_dataset = OpenStreetMap(\n",
    "        paths=os.path.join(WORK_DIR, folder[i], 'labels'), bbox=bbox_d, classes=OSM_CLASSES, download=True\n",
    "    )\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Intersection Dataset & Sampler\n",
    "\n",
    "We use the `&` operator to create an IntersectionDataset. This ensures every sample contains both imagery and a corresponding mask. this is done inside the package , lets initialize the configuration with dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(data_root=PosixPath('data/banepa'), output_dir='outputs/banepa_experiment', seed=64, train_regions=['train'], val_regions=['val'], test_regions=['test'], val_split=0.2, pretrained_model='facebook/mask2former-swin-base-IN21k-coco-instance', epochs=10, batch_size=8, dice_weight=5.0, mask_weight=5.0, class_weight=5.0, learning_rate=1e-05, weight_decay=0.0001, early_stopping_patience=10, num_workers=31, use_wandb=True, wandb_project='building-seg-mask2former', wandb_run_name='notebook_run_banepa')\n"
     ]
    }
   ],
   "source": [
    "from src.config import Config\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "cfg.data_root = WORK_DIR\n",
    "cfg.output_dir = 'outputs/banepa_experiment'\n",
    "cfg.train_regions = ['train']\n",
    "cfg.val_regions = ['val']\n",
    "cfg.test_regions = ['test']\n",
    "cfg.wandb_run_name='notebook_run_banepa'\n",
    "\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Setup\n",
    "\n",
    "mask2former swin backbone , coco instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/transformers/image_processing_base.py:417: UserWarning: The following named arguments are not valid for `Mask2FormerImageProcessor.__init__` and were ignored: '_max_size', 'reduce_labels'\n",
      "  image_processor = cls(**image_processor_dict)\n",
      "Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-base-IN21k-coco-instance and are newly initialized because the shapes did not match:\n",
      "- class_predictor.weight: found shape torch.Size([81, 256]) in the checkpoint and torch.Size([3, 256]) in the model instantiated\n",
      "- class_predictor.bias: found shape torch.Size([81]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- criterion.empty_weight: found shape torch.Size([81]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import set_seed\n",
    "from src.stage1_foundation import Mask2FormerModule\n",
    "from src.stage1_foundation import OAMDataModule\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "model = Mask2FormerModule(cfg)\n",
    "datamodule = OAMDataModule(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/krschap/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkrschap\u001b[0m (\u001b[33mkrschap-ubs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb/run-20260127_002726-3bblal9s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/krschap-ubs/building-seg-mask2former/runs/3bblal9s' target=\"_blank\">notebook_run_banepa</a></strong> to <a href='https://wandb.ai/krschap-ubs/building-seg-mask2former' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/krschap-ubs/building-seg-mask2former' target=\"_blank\">https://wandb.ai/krschap-ubs/building-seg-mask2former</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/krschap-ubs/building-seg-mask2former/runs/3bblal9s' target=\"_blank\">https://wandb.ai/krschap-ubs/building-seg-mask2former/runs/3bblal9s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding image,label path for ['train']...\n",
      "Loading images ...\n",
      "Loaded 378 image tiles. using crs : GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] with res (1.341104507446289e-06, 1.1881033085345272e-06)\n",
      "Loading labels ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/krschap/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type                                | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------------------------------\n",
      "0 | model         | Mask2FormerForUniversalSegmentation | 106 M  | eval  | 0    \n",
      "1 | train_metrics | MetricCollection                    | 0      | train | 0    \n",
      "2 | val_metrics   | MetricCollection                    | 0      | train | 0    \n",
      "3 | test_metrics  | MetricCollection                    | 0      | train | 0    \n",
      "--------------------------------------------------------------------------------------\n",
      "106 M     Trainable params\n",
      "0         Non-trainable params\n",
      "106 M     Total params\n",
      "427.537   Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "719       Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 mask tiles. using crs : EPSG:4326 with res (0.0001, 0.0001)\n",
      "Converting RAMPMaskDataset res from (0.0001, 0.0001) to (1.341104507446289e-06, 1.1881033085345272e-06)\n",
      "Train dataset length: 378\n",
      "Finding image,label path for ['val']...\n",
      "Loading images ...\n",
      "Loaded 40 image tiles. using crs : GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] with res (1.341104507446289e-06, 1.188076889681311e-06)\n",
      "Loading labels ...\n",
      "Loaded 1 mask tiles. using crs : EPSG:4326 with res (0.0001, 0.0001)\n",
      "Converting RAMPMaskDataset res from (0.0001, 0.0001) to (1.341104507446289e-06, 1.188076889681311e-06)\n",
      "Val dataset length: 40\n",
      "Finding image,label path for ['test']...\n",
      "Loading images ...\n",
      "Loaded 72 image tiles. using crs : GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] with res (1.341104507446289e-06, 1.1881759523699187e-06)\n",
      "Loading labels ...\n",
      "Loaded 1 mask tiles. using crs : EPSG:4326 with res (0.0001, 0.0001)\n",
      "Converting RAMPMaskDataset res from (0.0001, 0.0001) to (1.341104507446289e-06, 1.1881759523699187e-06)\n",
      "Test dataset length: 72\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]val_sampler length 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sampler length 2184                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "/home/krschap/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:534: Found 719 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 273/273 [02:08<00:00,  2.12it/s, v_num=al9s, train_loss=42.30, val_acc=0.940, val_f1=0.901, val_p=0.876, val_r=0.928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 273/273 [02:08<00:00,  2.12it/s, v_num=al9s, train_loss=42.30, val_acc=0.940, val_f1=0.901, val_p=0.876, val_r=0.928]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=cfg.early_stopping_patience,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=cfg.output_dir,\n",
    "        filename=\"best\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "    ),\n",
    "]\n",
    "\n",
    "logger = (\n",
    "    WandbLogger(project=cfg.wandb_project, name=cfg.wandb_run_name)\n",
    "    if cfg.use_wandb\n",
    "    else None\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    precision=\"16-mixed\",\n",
    "    default_root_dir=cfg.output_dir,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding image,label path for ['train']...\n",
      "Loading images ...\n",
      "Loaded 378 image tiles. using crs : GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] with res (1.341104507446289e-06, 1.1881033085345272e-06)\n",
      "Loading labels ...\n",
      "Loaded 1 mask tiles. using crs : EPSG:4326 with res (0.0001, 0.0001)\n",
      "Converting RAMPMaskDataset res from (0.0001, 0.0001) to (1.341104507446289e-06, 1.1881033085345272e-06)\n",
      "Train dataset length: 378\n",
      "Finding image,label path for ['val']...\n",
      "Loading images ...\n",
      "Loaded 40 image tiles. using crs : GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] with res (1.341104507446289e-06, 1.188076889681311e-06)\n",
      "Loading labels ...\n",
      "Loaded 1 mask tiles. using crs : EPSG:4326 with res (0.0001, 0.0001)\n",
      "Converting RAMPMaskDataset res from (0.0001, 0.0001) to (1.341104507446289e-06, 1.188076889681311e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/krschap/foss/high-res-building-seg-swinv2-mask2former/outputs/banepa_experiment/best.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val dataset length: 40\n",
      "Finding image,label path for ['test']...\n",
      "Loading images ...\n",
      "Loaded 72 image tiles. using crs : GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] with res (1.341104507446289e-06, 1.1881759523699187e-06)\n",
      "Loading labels ...\n",
      "Loaded 1 mask tiles. using crs : EPSG:4326 with res (0.0001, 0.0001)\n",
      "Converting RAMPMaskDataset res from (0.0001, 0.0001) to (1.341104507446289e-06, 1.1881759523699187e-06)\n",
      "Test dataset length: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/krschap/foss/high-res-building-seg-swinv2-mask2former/outputs/banepa_experiment/best.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sampler length 414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/pytorch_lightning/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 51/51 [00:07<00:00,  6.63it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9309656620025635\n",
      "         test_f1            0.8441967368125916\n",
      "        test_loss            25.70064926147461\n",
      "         test_p             0.7793942093849182\n",
      "         test_r             0.9207524657249451\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 25.70064926147461,\n",
       "  'test_acc': 0.9309656620025635,\n",
       "  'test_f1': 0.8441967368125916,\n",
       "  'test_p': 0.7793942093849182,\n",
       "  'test_r': 0.9207524657249451}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule, ckpt_path=\"best\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "high-res-building-seg-swinv2-mask2former",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
